{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3+LFf+pz0heS3ZNzaYjvu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Phani-Raja-Bharath/AI-assisted-Data-Center-prompt-routing/blob/main/Memory_Requirements.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c80c044c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dcR3R-2u5C9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/NYC_TLC_Python_Colab_Notebooks/nyc_taxi_zinb_ready.csv')\n",
        "\n",
        "# Count ACTUAL locations with data\n",
        "actual_locs = len(df[['grid_x', 'grid_y']].drop_duplicates())\n",
        "\n",
        "# Count total observations\n",
        "total_obs = len(df)\n",
        "\n",
        "# Memory calculation\n",
        "mem_gb = (actual_locs**2 * 4 * 8) / (1024**3)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\" CRITICAL DATA ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Grid dimensions: {df['grid_x'].max()+1} × {df['grid_y'].max()+1}\")\n",
        "print(f\"Maximum possible locations: {(df['grid_x'].max()+1) * (df['grid_y'].max()+1):,}\")\n",
        "print()\n",
        "print(f\"ACTUAL locations with data: {actual_locs:,}\")\n",
        "print(f\"Total observations: {total_obs:,}\")\n",
        "print(f\"Sparsity: {100 * actual_locs / ((df['grid_x'].max()+1) * (df['grid_y'].max()+1)):.1f}% of grid has data\")\n",
        "print()\n",
        "print(f\"GPU memory needed: {mem_gb:.1f} GB\")\n",
        "print()\n",
        "\n",
        "if mem_gb > 15:\n",
        "    print(\"❌ TOO LARGE FOR ANY GPU!\")\n",
        "    safe_locs = int(actual_locs * (12/mem_gb)**0.5)\n",
        "    loss_pct = 100 * (1 - safe_locs/actual_locs)\n",
        "    print(f\"   Would need to subsample to {safe_locs} locations\")\n",
        "    print(f\"   Loss: {loss_pct:.1f}% of data\")\n",
        "    print()\n",
        "    print(\"RECOMMENDATION:\")\n",
        "    print(f\"  Option A: GPU with {safe_locs} locations (10-20 min, {loss_pct:.0f}% data loss)\")\n",
        "    print(f\"  Option B: CPU with all {actual_locs} locations (2-6 hours, NO loss)\")\n",
        "\n",
        "elif mem_gb > 12:\n",
        "    print(\"⚠️ BORDERLINE - Might fit on T4 GPU\")\n",
        "    print(\"   May need slight subsampling or will work on CPU\")\n",
        "\n",
        "else:\n",
        "    print(\"✓ PERFECT SIZE - Will fit on T4 GPU!\")\n",
        "    print(f\"   Expected runtime: 10-20 minutes with all {actual_locs} locations\")\n",
        "\n",
        "print(\"=\"*70)"
      ]
    }
  ]
}